Title: Getting AWS setup and the basics of attention
Date: 8th June 2017

Great turn out this week and fantastic to see so many new faces.
For Session One this week Alan did a great job of talking us through his trails and tribulations in getting AWS setup from a windows platform. The key takeaways were: Use the Windows Bash shell as opposed to cygwin and how transfer learning can reduce the amount of computation you need to perform, meaning that you can run these models just on your PC, albeit slowly. Finally we concluded can that for lesson 1 probabilistically it can be hard to tell a cat from a plastic bag.

For Session Two, the more advanced session, after many AV issues we only had time for one talk on the "basics of attention" We covered at a high level attention for context and location, soft and hard attention. The talk assumed a knowledge of lstm sequence to sequence models and showed, hopefully, seq - seq encoder decoder networks use attention to define context and location for nlp and vision.
The references for this talk are below:

Next week:
Sessions one will cover lesson three as group learning session.
Session Two will he a talk on Embeddings by Michael.


# References:
[Attention and Augmented Recurrent Neural Networks
Chris Olah, Shan Carter](http://distill.pub/2016/augmented-rnns/)

[Effective Approaches to Attention-based Neural Machine Translation
Minh-Thang Luong Hieu Pham Christopher D. Manning]( https://arxiv.org/pdf/1508.04025.pdf)

[Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
Yoshua Bengio et al.]( https://arxiv.org/pdf/1502.03044.pdf)

[Kyunghyun Cho p1](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/)
[p2](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/)
[p3](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/)

[vid](https://www.youtube.com/watch?v=omHLeV1aicw)
[attention models](https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-attention-models-upc-2016)

[vid](https://www.youtube.com/watch?v=IxQtK2SjWWM#t=6.055047)

[Stanford CS231n lecture course notes](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)

[Hard Attention
DRAW: A Recurrent Neural Network For Image Generation
Alex Graves et al.](https://arxiv.org/pdf/1502.04623.pdf)

[Spatial Transformer Networks
Max Jaderberg Karen Simonyan Andrew Zisserman Koray Kavukcuoglu](https://arxiv.org/pdf/1506.02025.pdf)

[Visual7W: Grounded Question Answering in Images
Yuke Zhu Oliver Groth Michael Bernstein Li Fei-Fei](https://arxiv.org/pdf/1511.03416.pdf)

[Soft Attention
Action recognition using visual attention
Shikhar Sharma, Ryan Kiros & Ruslan Salakhutdinov](https://arxiv.org/pdf/1511.04119.pdf)

[Recurrent Attentional Networks for Saliency Detection
Jason Kuen, Zhenhua Wang, Gang Wang](https://arxiv.org/pdf/1604.03227.pdf)

[Attention to Scale: Scale-aware Semantic Image Segmentation
Liang-Chieh Chen et al.](https://arxiv.org/pdf/1511.03339.pdf)

[Image Captioning with Semantic Attention
Quanzeng You at al.](https://arxiv.org/pdf/1603.03925.pdf
)
