<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Perth Machine Learning Group</title><link href="http://pmlg.github.io/" rel="alternate"></link><link href="http://pmlg.github.io/feeds/all.atom.xml" rel="self"></link><id>http://pmlg.github.io/</id><updated>2017-06-22T00:00:00+08:00</updated><entry><title>Applying Embeddings to DNA KMer Matching</title><link href="http://pmlg.github.io/applying-embeddings-to-dna-kmer-matching.html" rel="alternate"></link><published>2017-06-22T00:00:00+08:00</published><updated>2017-06-22T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-06-22:/applying-embeddings-to-dna-kmer-matching.html</id><summary type="html">&lt;p&gt;This week we began with code from the fast.ai course in the beginners
session (6-7).  In the advanced session (7-8) we listened to an actual
bio-informatics guru Phillipp Bayer talking about applying embeddings
to DNA kmer matching as inspired by Mike's talk last week.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/philippbayer/cats_dogs_redux/blob/master/Embeddings%20%2B%20keras.ipynb"&gt;Jupyter notebook from talk &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1701.06279 https://github.com/pnpnpn/dna2vec"&gt;The …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week we began with code from the fast.ai course in the beginners
session (6-7).  In the advanced session (7-8) we listened to an actual
bio-informatics guru Phillipp Bayer talking about applying embeddings
to DNA kmer matching as inspired by Mike's talk last week.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/philippbayer/cats_dogs_redux/blob/master/Embeddings%20%2B%20keras.ipynb"&gt;Jupyter notebook from talk &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1701.06279 https://github.com/pnpnpn/dna2vec"&gt;The paper and code (the word2vec paper is also here)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://fivethirtyeight.com/features/dissecting-trumps-most-rabid-online-following/"&gt;This is the wonderful article on using arithmetic similar to word2vec to compare (hate-)subreddits&lt;/a&gt;
(could be interesting to do this with DNA from different plants to see what falls out)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://rcc.uq.edu.au/flashlite"&gt;This is the high memory cluster&lt;/a&gt;
You can apply for access if you have an Australian Access Federation (AAF) account, i.e., if you work for CSIRO or any Australian research institute.&lt;/p&gt;
&lt;p&gt;Here in Perth there's &lt;a href="https://www.pawsey.org.au/2016/09/applications-now-open-2017-access-to-pawsey-supercomputers/"&gt;Pawsey Centre&lt;/a&gt;:
Looks like you need to be part of an Australian research institute as well to be eligible.&lt;/p&gt;</content></entry><entry><title>Getting AWS setup and the basics of attention</title><link href="http://pmlg.github.io/getting-aws-setup-and-the-basics-of-attention.html" rel="alternate"></link><published>2017-06-08T00:00:00+08:00</published><updated>2017-06-08T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-06-08:/getting-aws-setup-and-the-basics-of-attention.html</id><summary type="html">&lt;p&gt;Great turn out this week and fantastic to see so many new faces.
For Session One this week Alan did a great job of talking us through his trails and tribulations in getting AWS setup from a windows platform. The key takeaways were: Use the Windows Bash shell as opposed …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Great turn out this week and fantastic to see so many new faces.
For Session One this week Alan did a great job of talking us through his trails and tribulations in getting AWS setup from a windows platform. The key takeaways were: Use the Windows Bash shell as opposed to cygwin and how transfer learning can reduce the amount of computation you need to perform, meaning that you can run these models just on your PC, albeit slowly. Finally we concluded can that for lesson 1 probabilistically it can be hard to tell a cat from a plastic bag.&lt;/p&gt;
&lt;p&gt;For Session Two, the more advanced session, after many AV issues we only had time for one talk on the "basics of attention" We covered at a high level attention for context and location, soft and hard attention. The talk assumed a knowledge of lstm sequence to sequence models and showed, hopefully, seq - seq encoder decoder networks use attention to define context and location for nlp and vision.
The references for this talk are below:&lt;/p&gt;
&lt;p&gt;Next week:
Sessions one will cover lesson three as group learning session.
Session Two will he a talk on Embeddings by Michael.&lt;/p&gt;
&lt;h1&gt;References:&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://distill.pub/2016/augmented-rnns/"&gt;Attention and Augmented Recurrent Neural Networks
Chris Olah, Shan Carter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1508.04025.pdf"&gt;Effective Approaches to Attention-based Neural Machine Translation
Minh-Thang Luong Hieu Pham Christopher D. Manning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1502.03044.pdf"&gt;Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
Yoshua Bengio et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/"&gt;Kyunghyun Cho p1&lt;/a&gt;
&lt;a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/"&gt;p2&lt;/a&gt;
&lt;a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/"&gt;p3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=omHLeV1aicw"&gt;vid&lt;/a&gt;
&lt;a href="https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-attention-models-upc-2016"&gt;attention models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=IxQtK2SjWWM#t=6.055047"&gt;vid&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf"&gt;Stanford CS231n lecture course notes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1502.04623.pdf"&gt;Hard Attention
DRAW: A Recurrent Neural Network For Image Generation
Alex Graves et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1506.02025.pdf"&gt;Spatial Transformer Networks
Max Jaderberg Karen Simonyan Andrew Zisserman Koray Kavukcuoglu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1511.03416.pdf"&gt;Visual7W: Grounded Question Answering in Images
Yuke Zhu Oliver Groth Michael Bernstein Li Fei-Fei&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1511.04119.pdf"&gt;Soft Attention
Action recognition using visual attention
Shikhar Sharma, Ryan Kiros &amp;amp; Ruslan Salakhutdinov&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1604.03227.pdf"&gt;Recurrent Attentional Networks for Saliency Detection
Jason Kuen, Zhenhua Wang, Gang Wang&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1511.03339.pdf"&gt;Attention to Scale: Scale-aware Semantic Image Segmentation
Liang-Chieh Chen et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1603.03925.pdf"&gt;Image Captioning with Semantic Attention
Quanzeng You at al.&lt;/a&gt;&lt;/p&gt;</content></entry><entry><title>How to use AWS? How to teach speech?</title><link href="http://pmlg.github.io/how-to-use-aws-how-to-teach-speech.html" rel="alternate"></link><published>2017-06-01T00:00:00+08:00</published><updated>2017-06-01T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-06-01:/how-to-use-aws-how-to-teach-speech.html</id><summary type="html">&lt;p&gt;Thanks to speakers today Austin and Michael, and thank you to all those attending...special thanks to Jennifer for the treats.&lt;/p&gt;
&lt;h2&gt;June 1st meetup&lt;/h2&gt;
&lt;p&gt;Austin took us through session 1 and the trials and tribulations of setting up AWS. We discussed how to divide up data into test train and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Thanks to speakers today Austin and Michael, and thank you to all those attending...special thanks to Jennifer for the treats.&lt;/p&gt;
&lt;h2&gt;June 1st meetup&lt;/h2&gt;
&lt;p&gt;Austin took us through session 1 and the trials and tribulations of setting up AWS. We discussed how to divide up data into test train and validate and data folders. Then moved onto discuss the idea transfer learning or using a network trained on one set of data to classify another set of data, in our case cats and dogs.&lt;/p&gt;
&lt;p&gt;In session 2 Michael took us through some very cool code he had written for phoneme to grapheme translation showing interesting results. After asking why? We discussed modification to the network via embeddings, BiLSTM and attention, convolutional variants, Differentiable Neural Computers (because) and mixed length filters in conv nets.&lt;/p&gt;
&lt;h2&gt;Next week&lt;/h2&gt;
&lt;p&gt;Session 1 will be a group help out lesson for getting some of our new members people started onto the Fast AI course.
Session 2 will be a discussion on attention and embedding. Michael will be running through some material on embedding while Sean tackles attention.&lt;/p&gt;
&lt;p&gt;See you next week&lt;/p&gt;</content></entry><entry><title>Deep Learning with Sound and Lesson 4</title><link href="http://pmlg.github.io/deep-learning-with-sound-and-lesson-4.html" rel="alternate"></link><published>2017-05-25T00:00:00+08:00</published><updated>2017-05-25T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-05-25:/deep-learning-with-sound-and-lesson-4.html</id><summary type="html">&lt;p&gt;Great meet up last week, thanks Grant and John for taking us through your recent work.
In the meet up we covered part of lesson 4 with a focus on &lt;a href="https://en.m.wikipedia.org/wiki/Collaborative_filtering"&gt;collaborative filtering&lt;/a&gt; and briefly touching on the area of &lt;a href="https://github.com/fastai/courses/blob/master/deeplearning1/excel/collab_filter.xlsx"&gt;embeddings&lt;/a&gt; &lt;a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/"&gt;NLP Representations&lt;/a&gt;
&lt;a href="https://www.tensorflow.org/tutorials/word2vec"&gt;word2vec&lt;/a&gt; Note these links just scratch the surface …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Great meet up last week, thanks Grant and John for taking us through your recent work.
In the meet up we covered part of lesson 4 with a focus on &lt;a href="https://en.m.wikipedia.org/wiki/Collaborative_filtering"&gt;collaborative filtering&lt;/a&gt; and briefly touching on the area of &lt;a href="https://github.com/fastai/courses/blob/master/deeplearning1/excel/collab_filter.xlsx"&gt;embeddings&lt;/a&gt; &lt;a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/"&gt;NLP Representations&lt;/a&gt;
&lt;a href="https://www.tensorflow.org/tutorials/word2vec"&gt;word2vec&lt;/a&gt; Note these links just scratch the surface. Embeddings are a very rich area of research.&lt;/p&gt;
&lt;p&gt;In session 2 John took us through the interesting area of using conv nets to process sound and potential for running this on embedded devices. This work was done over a weekend for the Unearthed Perth hackerthon. Here is a picture from the competition of the Pi calculating a realtime spectrogram (courtesy of Sam Bishop) which was then run through the conv net.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Deep Learning on RPi" src="images/rpinet.jpg"&gt;&lt;/p&gt;
&lt;p&gt;and we wound up the session with a recent paper from google on learning joint sound and vision on &lt;a href="https://arxiv.org/pdf/1705.08168.pdf"&gt;Conv nets&lt;/a&gt;, &lt;a href="https://github.com/pmlg/notebooks/blob/master/Convert%20Soundnet%20to%20Keras.ipynb"&gt;notebook&lt;/a&gt;
This coming Thursday speakers are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Austin Shen will lead us through session 1&lt;/li&gt;
&lt;li&gt;Michael Clark will lead us though session 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking forward to seeing you folk on Thursday.&lt;/p&gt;</content></entry><entry><title>Deep Networks for Financial Markets</title><link href="http://pmlg.github.io/deep-networks-for-financial-markets.html" rel="alternate"></link><published>2017-05-18T00:00:00+08:00</published><updated>2017-05-18T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-05-18:/deep-networks-for-financial-markets.html</id><summary type="html">&lt;p&gt;Last week we heard from Sarada on her tips for how to get started with
deep learning and getting the most out of the fast.ai course. That was
followed by Darcy who explored using a Seq2Seq model for fungal gene sequencing.&lt;/p&gt;
&lt;p&gt;This week we looked at financial modelling, being …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week we heard from Sarada on her tips for how to get started with
deep learning and getting the most out of the fast.ai course. That was
followed by Darcy who explored using a Seq2Seq model for fungal gene sequencing.&lt;/p&gt;
&lt;p&gt;This week we looked at financial modelling, being led by Shereif. He has produced this &lt;a href="https://github.com/pmlg/notebooks/blob/master/IndicatorsNN.ipynb"&gt;Jupyter Notebook&lt;/a&gt;, and led us through his thinking. Pull requests welcome!&lt;/p&gt;</content></entry><entry><title>Lesson 7 and Group Poll</title><link href="http://pmlg.github.io/lesson-7-and-group-poll.html" rel="alternate"></link><published>2017-05-11T00:00:00+08:00</published><updated>2017-05-11T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-05-11:/lesson-7-and-group-poll.html</id><summary type="html">&lt;p&gt;Last week we had a great turn out, with 15 people attending. In the
beginner session we explored the basics of CNN's as well as looking
into the implementation of VGG from
the &lt;a href="http://course.fast.ai"&gt;fast.ai&lt;/a&gt; course. While in the advanced
session we finally finished RNN's.&lt;/p&gt;
&lt;p&gt;We also discussed doing a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week we had a great turn out, with 15 people attending. In the
beginner session we explored the basics of CNN's as well as looking
into the implementation of VGG from
the &lt;a href="http://course.fast.ai"&gt;fast.ai&lt;/a&gt; course. While in the advanced
session we finally finished RNN's.&lt;/p&gt;
&lt;p&gt;We also discussed doing a group project. Please use this doodle &lt;a href="http://doodle.com/poll/hay95h9yvdpw98ud"&gt;poll&lt;/a&gt; to indicate your preference. The competitions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening"&gt;Cervical Cancer Screening&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/youtube8m"&gt;Google Cloud YouTube8m Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space"&gt;Understanding Amazon from Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/sberbank-russian-housing-market"&gt;Russian Housing Market&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count"&gt;Counting Sea Lions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/quora-question-pairs"&gt;Question answer Pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.synapse.org/#!Synapse:syn4224222/wiki/"&gt;Digital Mammography DREAM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, this week in the advanced session we will explore lesson 7. The wrap up to part 1 of the Fast.ai course.&lt;/p&gt;</content></entry><entry><title>RNN's and Jupyter Notebook Hints</title><link href="http://pmlg.github.io/rnns-and-jupyter-notebook-hints.html" rel="alternate"></link><published>2017-04-27T00:00:00+08:00</published><updated>2017-04-27T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-04-27:/rnns-and-jupyter-notebook-hints.html</id><summary type="html">&lt;p&gt;This week in the beginner session we explored some tips and tricks for
getting the most out of Jupyter Notebook. We also looked at how to
answer the question, "what libraries are even installed".&lt;/p&gt;
&lt;p&gt;In the advanced hour we continued our exploration of RNN's. We
examined how you can produce …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week in the beginner session we explored some tips and tricks for
getting the most out of Jupyter Notebook. We also looked at how to
answer the question, "what libraries are even installed".&lt;/p&gt;
&lt;p&gt;In the advanced hour we continued our exploration of RNN's. We
examined how you can produce a sequence of outputs from an RNN and
discussed how the keras implementation of RNN's works. Next week we
will go through LSTM's.&lt;/p&gt;</content></entry><entry><title>Catchup Summary</title><link href="http://pmlg.github.io/catchup-summary.html" rel="alternate"></link><published>2017-04-20T10:20:00+08:00</published><updated>2017-04-20T10:20:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-04-20:/catchup-summary.html</id><summary type="html">&lt;p&gt;This week in the Perth Deep Learning Group we finished off exploring the concepts of
Batch Normalization, Drop-out and Activation functions.&lt;/p&gt;
&lt;p&gt;In the advanced section we examined how Recurrent Neural networks work by exploring
the first parts of the Lesson 6 notebooks.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week in the Perth Deep Learning Group we finished off exploring the concepts of
Batch Normalization, Drop-out and Activation functions.&lt;/p&gt;
&lt;p&gt;In the advanced section we examined how Recurrent Neural networks work by exploring
the first parts of the Lesson 6 notebooks.&lt;/p&gt;</content></entry><entry><title>Deep Learning Summary</title><link href="http://pmlg.github.io/deep-learning-summary.html" rel="alternate"></link><published>2017-04-04T00:00:00+08:00</published><updated>2017-04-04T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-04-04:/deep-learning-summary.html</id><summary type="html">&lt;p&gt;Last week during the beginner hour we explored the basics of lesson
1's use of the VGG network.&lt;/p&gt;
&lt;p&gt;In the advanced section Sharif was kind enough to explain his approach
to the Quora question and answers problem on Kaggle.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week during the beginner hour we explored the basics of lesson
1's use of the VGG network.&lt;/p&gt;
&lt;p&gt;In the advanced section Sharif was kind enough to explain his approach
to the Quora question and answers problem on Kaggle.&lt;/p&gt;</content></entry><entry><title>Next Deep Learning Meeting</title><link href="http://pmlg.github.io/next-deep-learning-meeting.html" rel="alternate"></link><published>2017-03-30T00:00:00+08:00</published><updated>2017-03-30T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.github.io,2017-03-30:/next-deep-learning-meeting.html</id><summary type="html">&lt;p&gt;Hi Perth Deep Learners,&lt;/p&gt;
&lt;p&gt;We've changed the format. Instead of going through each lecture from
the mooc, we are splitting our time into two slots, a beginner
session, from 6-7pm, and an advanced session from 7-8pm.&lt;/p&gt;
&lt;p&gt;If you are a beginner and haven't been following the course, please
come to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hi Perth Deep Learners,&lt;/p&gt;
&lt;p&gt;We've changed the format. Instead of going through each lecture from
the mooc, we are splitting our time into two slots, a beginner
session, from 6-7pm, and an advanced session from 7-8pm.&lt;/p&gt;
&lt;p&gt;If you are a beginner and haven't been following the course, please
come to the beginner session, we will happily go over the basics and
help you come up to speed. No homework required!&lt;/p&gt;
&lt;p&gt;For the advanced session, it will be a discussion group around some
advanced topics. Last week we:
- Explored an application of Deep Learning in Biology lead by Darcy
- Learnt more about what you actually get when you ask for a p2.xlarge
instance from amazon.
- Explored what a de-convolution means.
- Explored what an embedding means in a biology domain.&lt;/p&gt;
&lt;p&gt;In this weeks advanced session I'll start by giving a walk through
lesson 6 on RNN's and LSTM's as well as give a quick overview of my
experience dabbling with Tensorflow.&lt;/p&gt;</content></entry></feed>