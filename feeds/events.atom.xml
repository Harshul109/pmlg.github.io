<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Perth Machine Learning Group - events</title><link href="http://pmlg.org/" rel="alternate"></link><link href="http://pmlg.org/feeds/events.atom.xml" rel="self"></link><id>http://pmlg.org/</id><updated>2017-05-25T00:00:00+08:00</updated><entry><title>Deep Learning with Sound and Lesson 4</title><link href="http://pmlg.org/deep-learning-with-sound-and-lesson-4.html" rel="alternate"></link><published>2017-05-25T00:00:00+08:00</published><updated>2017-05-25T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-05-25:/deep-learning-with-sound-and-lesson-4.html</id><summary type="html">&lt;p&gt;Great meet up last week, thanks Grant and John for taking us through your recent work.
In the meet up we covered part of lesson 4 with a focus on &lt;a href="https://en.m.wikipedia.org/wiki/Collaborative_filtering"&gt;collaborative filtering&lt;/a&gt; and briefly touching on the area of &lt;a href="https://github.com/fastai/courses/blob/master/deeplearning1/excel/collab_filter.xlsx"&gt;embeddings&lt;/a&gt; &lt;a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/"&gt;NLP Representations&lt;/a&gt;
&lt;a href="https://www.tensorflow.org/tutorials/word2vec"&gt;word2vec&lt;/a&gt; Note these links just scratch the surface …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Great meet up last week, thanks Grant and John for taking us through your recent work.
In the meet up we covered part of lesson 4 with a focus on &lt;a href="https://en.m.wikipedia.org/wiki/Collaborative_filtering"&gt;collaborative filtering&lt;/a&gt; and briefly touching on the area of &lt;a href="https://github.com/fastai/courses/blob/master/deeplearning1/excel/collab_filter.xlsx"&gt;embeddings&lt;/a&gt; &lt;a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/"&gt;NLP Representations&lt;/a&gt;
&lt;a href="https://www.tensorflow.org/tutorials/word2vec"&gt;word2vec&lt;/a&gt; Note these links just scratch the surface. Embeddings are a very rich area of research.&lt;/p&gt;
&lt;p&gt;In session 2 John took us through the interesting area of using conv nets to process sound and potential for running this on embedded devices. This work was done over a weekend for the Unearthed Perth hackerthon. Here is a picture from the competition of the Pi calculating a realtime spectrogram (courtesy of Sam Bishop) which was then run through the conv net.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Deep Learning on RPi" src="images/rpinet.jpg"&gt;&lt;/p&gt;
&lt;p&gt;and we wound up the session with a recent paper from google on learning joint sound and vision on &lt;a href="https://arxiv.org/pdf/1705.08168.pdf"&gt;Conv nets&lt;/a&gt;
This coming Thursday speakers are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Austin Shen will lead us through session 1&lt;/li&gt;
&lt;li&gt;Michael Clark will lead us though session 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking forward to seeing you folk on Thursday.&lt;/p&gt;
&lt;p&gt;Regards
Sean&lt;/p&gt;</content></entry><entry><title>Deep Networks for Financial Markets</title><link href="http://pmlg.org/deep-networks-for-financial-markets.html" rel="alternate"></link><published>2017-05-18T00:00:00+08:00</published><updated>2017-05-18T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-05-18:/deep-networks-for-financial-markets.html</id><summary type="html">&lt;p&gt;Last week we heard from Sarada on her tips for how to get started with
deep learning and getting the most out of the fast.ai course. That was
followed by Darcy who explored using a Seq2Seq model for fungal gene sequencing.&lt;/p&gt;
&lt;p&gt;This week we looked at financial modelling, being …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week we heard from Sarada on her tips for how to get started with
deep learning and getting the most out of the fast.ai course. That was
followed by Darcy who explored using a Seq2Seq model for fungal gene sequencing.&lt;/p&gt;
&lt;p&gt;This week we looked at financial modelling, being led by Shereif. He has produced this &lt;a href="https://github.com/pmlg/notebooks/blob/master/IndicatorsNN.ipynb"&gt;Jupyter Notebook&lt;/a&gt;, and led us through his thinking. Pull requests welcome!&lt;/p&gt;</content></entry><entry><title>Lesson 7 and Group Poll</title><link href="http://pmlg.org/lesson-7-and-group-poll.html" rel="alternate"></link><published>2017-05-11T00:00:00+08:00</published><updated>2017-05-11T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-05-11:/lesson-7-and-group-poll.html</id><summary type="html">&lt;p&gt;Last week we had a great turn out, with 15 people attending. In the
beginner session we explored the basics of CNN's as well as looking
into the implementation of VGG from
the &lt;a href="http://course.fast.ai"&gt;fast.ai&lt;/a&gt; course. While in the advanced
session we finally finished RNN's.&lt;/p&gt;
&lt;p&gt;We also discussed doing a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week we had a great turn out, with 15 people attending. In the
beginner session we explored the basics of CNN's as well as looking
into the implementation of VGG from
the &lt;a href="http://course.fast.ai"&gt;fast.ai&lt;/a&gt; course. While in the advanced
session we finally finished RNN's.&lt;/p&gt;
&lt;p&gt;We also discussed doing a group project. Please use this doodle &lt;a href="http://doodle.com/poll/hay95h9yvdpw98ud"&gt;poll&lt;/a&gt; to indicate your preference. The competitions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening"&gt;Cervical Cancer Screening&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/youtube8m"&gt;Google Cloud YouTube8m Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space"&gt;Understanding Amazon from Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/sberbank-russian-housing-market"&gt;Russian Housing Market&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/noaa-fisheries-steller-sea-lion-population-count"&gt;Counting Sea Lions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/c/quora-question-pairs"&gt;Question answer Pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.synapse.org/#!Synapse:syn4224222/wiki/"&gt;Digital Mammography DREAM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, this week in the advanced session we will explore lesson 7. The wrap up to part 1 of the Fast.ai course.&lt;/p&gt;</content></entry><entry><title>RNN's and Jupyter Notebook Hints</title><link href="http://pmlg.org/rnns-and-jupyter-notebook-hints.html" rel="alternate"></link><published>2017-04-27T00:00:00+08:00</published><updated>2017-04-27T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-04-27:/rnns-and-jupyter-notebook-hints.html</id><summary type="html">&lt;p&gt;This week in the beginner session we explored some tips and tricks for
getting the most out of Jupyter Notebook. We also looked at how to
answer the question, "what libraries are even installed".&lt;/p&gt;
&lt;p&gt;In the advanced hour we continued our exploration of RNN's. We
examined how you can produce …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week in the beginner session we explored some tips and tricks for
getting the most out of Jupyter Notebook. We also looked at how to
answer the question, "what libraries are even installed".&lt;/p&gt;
&lt;p&gt;In the advanced hour we continued our exploration of RNN's. We
examined how you can produce a sequence of outputs from an RNN and
discussed how the keras implementation of RNN's works. Next week we
will go through LSTM's.&lt;/p&gt;</content></entry><entry><title>Catchup Summary</title><link href="http://pmlg.org/catchup-summary.html" rel="alternate"></link><published>2017-04-20T10:20:00+08:00</published><updated>2017-04-20T10:20:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-04-20:/catchup-summary.html</id><summary type="html">&lt;p&gt;This week in the Perth Deep Learning Group we finished off exploring the concepts of
Batch Normalization, Drop-out and Activation functions.&lt;/p&gt;
&lt;p&gt;In the advanced section we examined how Recurrent Neural networks work by exploring
the first parts of the Lesson 6 notebooks.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week in the Perth Deep Learning Group we finished off exploring the concepts of
Batch Normalization, Drop-out and Activation functions.&lt;/p&gt;
&lt;p&gt;In the advanced section we examined how Recurrent Neural networks work by exploring
the first parts of the Lesson 6 notebooks.&lt;/p&gt;</content></entry><entry><title>Deep Learning Summary</title><link href="http://pmlg.org/deep-learning-summary.html" rel="alternate"></link><published>2017-04-04T00:00:00+08:00</published><updated>2017-04-04T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-04-04:/deep-learning-summary.html</id><summary type="html">&lt;p&gt;Last week during the beginner hour we explored the basics of lesson
1's use of the VGG network.&lt;/p&gt;
&lt;p&gt;In the advanced section Sharif was kind enough to explain his approach
to the Quora question and answers problem on Kaggle.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week during the beginner hour we explored the basics of lesson
1's use of the VGG network.&lt;/p&gt;
&lt;p&gt;In the advanced section Sharif was kind enough to explain his approach
to the Quora question and answers problem on Kaggle.&lt;/p&gt;</content></entry><entry><title>Next Deep Learning Meeting</title><link href="http://pmlg.org/next-deep-learning-meeting.html" rel="alternate"></link><published>2017-03-30T00:00:00+08:00</published><updated>2017-03-30T00:00:00+08:00</updated><author><name>PMLG</name></author><id>tag:pmlg.org,2017-03-30:/next-deep-learning-meeting.html</id><summary type="html">&lt;p&gt;Hi Perth Deep Learners,&lt;/p&gt;
&lt;p&gt;We've changed the format. Instead of going through each lecture from
the mooc, we are splitting our time into two slots, a beginner
session, from 6-7pm, and an advanced session from 7-8pm.&lt;/p&gt;
&lt;p&gt;If you are a beginner and haven't been following the course, please
come to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hi Perth Deep Learners,&lt;/p&gt;
&lt;p&gt;We've changed the format. Instead of going through each lecture from
the mooc, we are splitting our time into two slots, a beginner
session, from 6-7pm, and an advanced session from 7-8pm.&lt;/p&gt;
&lt;p&gt;If you are a beginner and haven't been following the course, please
come to the beginner session, we will happily go over the basics and
help you come up to speed. No homework required!&lt;/p&gt;
&lt;p&gt;For the advanced session, it will be a discussion group around some
advanced topics. Last week we:
- Explored an application of Deep Learning in Biology lead by Darcy
- Learnt more about what you actually get when you ask for a p2.xlarge
instance from amazon.
- Explored what a de-convolution means.
- Explored what an embedding means in a biology domain.&lt;/p&gt;
&lt;p&gt;In this weeks advanced session I'll start by giving a walk through
lesson 6 on RNN's and LSTM's as well as give a quick overview of my
experience dabbling with Tensorflow.&lt;/p&gt;</content></entry></feed>